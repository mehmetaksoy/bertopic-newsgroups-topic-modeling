{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 1: Gerekli Kütüphanelerin Kurulumu (Kararlı Bir Ortam Hedefleyerek)\n",
        "\n",
        "**Amaç:**\n",
        "Bu hücrenin temel amacı, BERTopic modeli ile konu modellemesi yapabilmek ve özellikle `gensim` kütüphanesinin gerektirdiği konu tutarlılığı metriklerini hesaplayabilmek için gerekli olan Python kütüphanelerini Google Colab ortamına kurmaktır. Ana hedef, daha önceki denemelerde karşılaşılan ABI (Application Binary Interface) uyumsuzluklarını (özellikle `numpy.dtype size changed` hatası) önleyecek, NumPy, Pandas, SciPy gibi temel sayısal kütüphaneler ile `gensim` ve `bertopic` arasında stabil bir çalışma ortamı oluşturmaktır.\n",
        "\n",
        "**Yapılacak İşlemler:**\n",
        "1.  **Çalışma Zamanını Sıfırlama (Önerilir):** Kuruluma başlamadan önce, Colab çalışma zamanının \"Çalışma Zamanı\" -> \"Çalışma zamanı bağlantısını kes ve sil\" yoluyla sıfırlanması önerilir. Bu, temiz bir başlangıç sağlar.\n",
        "2.  **Temel Sayısal Kütüphanelerin Kurulumu:** `pip install -q` komutu kullanılarak, önceki başarılı çalışmalarda kullanılan \"altın standart\" olarak kabul edilebilecek sürümler hedeflenerek aşağıdaki kütüphaneler kurulur:\n",
        "    * **NumPy:** `1.26.4` sürümü.\n",
        "    * **Pandas:** `2.2.2` sürümü.\n",
        "    * **SciPy:** Belirli bir sürüm belirtilmeden (pip'in NumPy/Pandas ile uyumlu olanı seçmesi beklenir).\n",
        "3.  **BERTopic ve Temel Bağımlılıklarının Kurulumu:** `bertopic`, `gensim` ve `nltk` kütüphaneleri birlikte kurulur. Bu adım, konu modellemesi ve metin işleme için gerekli temel araçları sağlar.\n",
        "4.  **Hugging Face Kütüphanelerinin Kurulumu:** Makine öğrenimi modelleri ve veri kümeleri için yaygın olarak kullanılan `datasets` ve `transformers` kütüphaneleri, uyumlulukları bilinen sürümlerle kurulur:\n",
        "    * **Datasets:** `3.6.0` sürümü.\n",
        "    * **Transformers:** `4.48.3` sürümü.\n",
        "5.  **Diğer Yardımcı Kütüphanelerin Kurulumu:** Veri işleme, makine öğrenimi ve görselleştirme için sıkça kullanılan `scikit-learn`, `matplotlib` ve `seaborn` kütüphaneleri kurulur.\n",
        "\n",
        "**Beklenen Sonuç:**\n",
        "Belirtilen kütüphane versiyonları Colab ortamına kurulacaktır. Kurulum sırasında, Colab'ın kendi içinde bulunan diğer paketlerle (örneğin `thinc`, `tsfresh`, `gcsfs`) ilgili bazı bağımlılık uyarıları görülebilir. Ancak temel hedefimiz, BERTopic ve `gensim`'in, özellikle NumPy ve SciPy gibi temel bağımlılıklarıyla uyumlu bir şekilde çalışmasını sağlamaktır.\n",
        "\n",
        "**Çok Önemli Sonraki Adım:**\n",
        "Bu hücrenin çalışması tamamlandıktan sonra, **Colab çalışma zamanını KESİNLİKLE yeniden başlatmanız gerekmektedir** (\"Çalışma Zamanı\" -> \"Çalışma zamanını yeniden başlat\" veya \"Runtime\" -> \"Restart runtime\"). Bu işlem, yapılan tüm kurulumların doğru bir şekilde etkinleşmesi için kritik öneme sahiptir. Yeniden başlattıktan sonra bu Hücre 1'i **tekrar çalıştırmayın** ve doğrudan Hücre 2'ye (Kütüphane Importları) geçin."
      ],
      "metadata": {
        "id": "gdYGPPCIq6_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 1: BERTopic için Gerekli Kütüphanelerin Kurulumu (\"Altın Standart\" Ortam Hedefi)\n",
        "# Bu hücreyi, \"Çalışma zamanını sıfırla\" (Disconnect and delete runtime) işlemi sonrası TEMİZ BİR OTURUMDA çalıştırın.\n",
        "\n",
        "print(\"BERTopic projesi için kütüphaneler, 'altın standart' versiyonlar hedeflenerek kuruluyor...\")\n",
        "\n",
        "# 1. Temel sayısal kütüphaneleri, önceki başarılı ortamlardaki versiyonlara sabitleyelim.\n",
        "!pip install -q numpy==1.26.4\n",
        "print(\"NumPy 1.26.4 kurulumu denendi.\")\n",
        "\n",
        "!pip install -q pandas==2.2.2\n",
        "print(\"Pandas 2.2.2 kurulumu denendi.\")\n",
        "\n",
        "!pip install -q scipy\n",
        "print(\"SciPy kurulumu/güncellemesi denendi.\")\n",
        "\n",
        "# 2. BERTopic ve ana bağımlılıklarını (gensim, nltk dahil) kuralım\n",
        "!pip install -q bertopic gensim nltk\n",
        "print(\"BERTopic, Gensim ve NLTK (ve temel bağımlılıkları) kurulumu/güncellemesi denendi.\")\n",
        "\n",
        "# 3. Hugging Face kütüphanelerini (belirlenen versiyonlar) kuralım\n",
        "!pip install -q datasets==3.6.0\n",
        "print(\"Datasets 3.6.0 kurulumu denendi.\")\n",
        "!pip install -q transformers==4.48.3\n",
        "print(\"Transformers 4.48.3 kurulumu denendi.\")\n",
        "\n",
        "# 4. Diğer yardımcı kütüphaneler\n",
        "!pip install -q scikit-learn matplotlib seaborn\n",
        "print(\"Scikit-learn, Matplotlib, Seaborn kurulumu/güncellemesi denendi.\")\n",
        "\n",
        "print(\"\\nKütüphane kurulumları (Hücre 1) tamamlandı.\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "print(\"!!! LÜTFEN ŞİMDİ Colab Çalışma Zamanını ('Runtime' -> 'Restart runtime')   !!!\")\n",
        "print(\"!!! KESİNLİKLE YENİDEN BAŞLATIN. Bu, kurulumların etkinleşmesi için gereklidir.!!!\")\n",
        "print(\"!!! Yeniden başlattıktan sonra bu Hücre 1'i TEKRAR ÇALIŞTIRMAYIN,          !!!\")\n",
        "print(\"!!! doğrudan Hücre 2'ye (Kütüphane Importları) geçin.                     !!!\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
      ],
      "metadata": {
        "id": "fGJS-ShYq8KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 2 (BERTopic): Tüm Kütüphanelerin Import Edilmesi ve Son Ortam Kontrolü\n",
        "\n",
        "* **Amaç:**\n",
        "    Hücre 1'deki kurulumlar ve ardından yapılan zorunlu çalışma zamanı yeniden başlatmasından sonra, BERTopic projesi için gerekli tüm kütüphanelerin Python ortamına hatasız bir şekilde dahil edildiğini teyit etmek. Kullanılan tüm ana kütüphanelerin nihai versiyonlarını belgelemek ve GPU gibi donanım kaynaklarının durumunu kontrol etmek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  BERTopic projesi için gerekli tüm ana kütüphaneler ve modüller (`bertopic`, `gensim`, `nltk`, `transformers`, `datasets`, `torch`, `numpy`, `pandas`, `sklearn`, `umap`, `hdbscan`, `sentence_transformers` vb.) `import` edilir.\n",
        "    2.  `nltk` için `punkt` (tokenizer için) ve `stopwords` kaynaklarının indirilmesi (eğer daha önce indirilmemişse) sağlanır.\n",
        "    3.  GPU varlığı kontrol edilir ve `device` ayarlanır.\n",
        "    4.  İmport edilen ana kütüphanelerin versiyonları ekrana yazdırılır.\n",
        "    5.  Kullanılacak cihaz ve GPU detayları gösterilir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar:**\n",
        "    * Tüm import işlemlerinin (özellikle `import bertopic` ve `import gensim`'in tetiklediği `pandas` ve `numpy` importları) **hatasız** bir şekilde tamamlanması. En son başarılı çalıştırmada, bu kurulum stratejisiyle `numpy.dtype size changed` hatasının **alınmadığı** görülmüştür.\n",
        "    * Kütüphane versiyonları listelenir (BERTopic 0.17.0, NumPy 1.26.4, Pandas 2.2.2, SciPy 1.13.1, Gensim 4.3.3 vb.).\n",
        "    * Çalışma ortamının BERTopic ile konu modellemesi ve metrik hesaplamaları için tamamen hazır olduğu doğrulanır.\n",
        "    "
      ],
      "metadata": {
        "id": "2V6tC9CrsT2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 2: Tüm Kütüphanelerin Import Edilmesi ve Son Ortam Kontrolü\n",
        "# Bu hücreyi, Hücre 1'deki kurulumlardan ve ardından ÇALIŞMA ZAMANINI YENİDEN BAŞLATTIKTAN SONRA çalıştırın.\n",
        "\n",
        "print(\"BERTopic projesi için tüm kütüphaneler import ediliyor ve versiyonlar kontrol ediliyor...\")\n",
        "error_during_final_imports = False\n",
        "try:\n",
        "    import bertopic\n",
        "    from bertopic import BERTopic # BERTopic sınıfını import et\n",
        "    from bertopic.representation import KeyBERTInspired # Hücre 4'te kullanılacak\n",
        "    import transformers\n",
        "    import datasets\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import scipy # Gensim ve diğerleri tarafından kullanılabilir\n",
        "    import sklearn\n",
        "    import matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import sys\n",
        "    import time\n",
        "    import umap\n",
        "    import hdbscan\n",
        "    import sentence_transformers\n",
        "    import gensim\n",
        "    from gensim.models.coherencemodel import CoherenceModel\n",
        "    from gensim.corpora.dictionary import Dictionary\n",
        "    import nltk\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from sklearn.datasets import fetch_20newsgroups # Hücre 3'te kullanılacak\n",
        "    from sklearn.feature_extraction.text import CountVectorizer # Hücre 4'te kullanılacak\n",
        "    from itertools import combinations # Hücre 5'te Jaccard için\n",
        "\n",
        "    print(\"\\nAna kütüphaneler başarıyla import edildi.\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"KULLANILAN NİHAİ KÜTÜPHANE VERSİYONLARI:\")\n",
        "    print(f\"  Python Versiyonu (sys.version): {sys.version.split()[0]}\")\n",
        "    if hasattr(bertopic, '__version__'): print(f\"  BERTopic: {bertopic.__version__}\")\n",
        "    else: print(\"  BERTopic: Import edildi (versiyon özelliği yok).\")\n",
        "    print(f\"  PyTorch: {torch.__version__}\")\n",
        "    print(f\"  Transformers: {transformers.__version__}\")\n",
        "    print(f\"  Datasets: {datasets.__version__}\")\n",
        "    print(f\"  Numpy: {np.__version__}\")\n",
        "    print(f\"  Pandas: {pd.__version__}\")\n",
        "    print(f\"  SciPy: {scipy.__version__}\")\n",
        "    if hasattr(sklearn, '__version__'): print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
        "    if hasattr(matplotlib, '__version__'): print(f\"  Matplotlib: {matplotlib.__version__}\")\n",
        "    if hasattr(sns, '__version__'): print(f\"  Seaborn: {sns.__version__}\")\n",
        "\n",
        "    if hasattr(umap, '__version__'): print(f\"  UMAP-learn: {umap.__version__}\")\n",
        "    elif umap: print(\"  UMAP: Import edildi (versiyon özelliği yok).\")\n",
        "    else: print(\"  UMAP: Import edilemedi.\")\n",
        "\n",
        "    if hasattr(hdbscan, '__version__'): print(f\"  HDBSCAN: {hdbscan.__version__}\")\n",
        "    elif hdbscan: print(\"  HDBSCAN: Import edildi (versiyon özelliği yok veya alınamadı).\")\n",
        "    else: print(\"  HDBSCAN: Import edilemedi.\")\n",
        "\n",
        "    if hasattr(sentence_transformers, '__version__'):\n",
        "        print(f\"  SentenceTransformers: {sentence_transformers.__version__}\")\n",
        "    elif sentence_transformers: print(\"  SentenceTransformers: Import edildi (versiyon özelliği yok).\")\n",
        "    else: print(\"  SentenceTransformers: Import edilemedi.\")\n",
        "\n",
        "    if hasattr(gensim, '__version__'): print(f\"  Gensim: {gensim.__version__}\")\n",
        "    elif gensim: print(\"  Gensim: Import edildi (versiyon özelliği yok).\")\n",
        "    else: print(\"  Gensim: Import edilemedi.\")\n",
        "\n",
        "    if hasattr(nltk, '__version__'): print(f\"  NLTK: {nltk.__version__}\")\n",
        "    elif nltk: print(\"  NLTK: Import edildi (versiyon özelliği yok).\")\n",
        "    else: print(\"  NLTK: Import edilemedi.\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"KULLANILACAK CİHAZ (PyTorch için): {device}\")\n",
        "    if device.type == 'cuda':\n",
        "        print(f\"  CUDA Versiyonu (torch.version.cuda): {torch.version.cuda}\")\n",
        "        print(f\"  cuDNN Versiyonu (torch.backends.cudnn.version()): {torch.backends.cudnn.version()}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    print(\"\\n--- NLTK Kaynakları Kontrol Ediliyor/İndiriliyor ---\")\n",
        "    try:\n",
        "        _ = word_tokenize(\"Test.\") # Test etmek için çağır\n",
        "        print(\"NLTK 'punkt' tokenizer zaten çalışır durumda veya indirildi.\")\n",
        "    except LookupError:\n",
        "        print(\"NLTK 'punkt' indiriliyor...\")\n",
        "        nltk.download('punkt', quiet=True)\n",
        "        print(\"NLTK 'punkt' indirildi.\")\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "        print(\"NLTK stopwords zaten mevcut.\")\n",
        "    except LookupError:\n",
        "        print(\"NLTK stopwords indiriliyor...\")\n",
        "        nltk.download('stopwords', quiet=True)\n",
        "        print(\"NLTK stopwords indirildi.\")\n",
        "\n",
        "\n",
        "except Exception as e_final_import:\n",
        "    print(f\"\\n!!! HATA: Nihai kütüphane importları sırasında bir sorun oluştu: {e_final_import}\")\n",
        "    import traceback\n",
        "    print(traceback.format_exc())\n",
        "    error_during_final_imports = True\n",
        "\n",
        "if not error_during_final_imports:\n",
        "    print(\"\\nTüm kütüphaneler başarıyla import edildi ve ortam BERTopic için HAZIR!\")\n",
        "else:\n",
        "    print(\"\\nNihai import kontrolünde sorunlar yaşandı. Lütfen yukarıdaki hata mesajlarını inceleyin.\")"
      ],
      "metadata": {
        "id": "AEYbDOOUsJ_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 3 (BERTopic): Veri Yükleme ve Hazırlık (20 Newsgroups)\n",
        "\n",
        "* **Amaç:**\n",
        "    BERTopic ile konu modellemesi yapmak üzere \"20 Newsgroups\" veri setini `scikit-learn` kütüphanesi aracılığıyla yüklemek ve modelin girdi olarak bekleyeceği metin dokümanları listesini hazırlamak.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  `sklearn.datasets.fetch_20newsgroups` fonksiyonu, `subset='all'` (tüm veri setini kullanmak için) ve `remove=('headers', 'footers', 'quotes')` (metinlerden başlık, alt bilgi ve alıntıları çıkarmak için) parametreleriyle çağrılarak veri seti yüklenir. Ayrıca, sonuçların tekrarlanabilirliği için `shuffle=True` ve `random_state=42` kullanılır.\n",
        "    2.  Yüklenen veri setinden metin dokümanları (`newsgroups_data.data`) `documents_ng` adlı bir Python listesine alınır.\n",
        "    3.  Orijinal kategori etiketleri (`newsgroups_data.target`) ve kategori isimleri (`newsgroups_data.target_names`) de ileride değerlendirme veya analiz için saklanır.\n",
        "    4.  Bu örnekte zaman damgası verisi kullanılmayacağı için `timestamps_ng` değişkeni `None` olarak ayarlanır.\n",
        "    5.  Toplam doküman sayısı ve ilk dokümandan bir örnek (orijinal kategorisiyle birlikte) ekrana yazdırılır.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar:**\n",
        "    * 20 Newsgroups veri setinin (yaklaşık 18,846 doküman) başarıyla yüklenmesi beklenir.\n",
        "    * `documents_ng` listesi, konu modellemesi için kullanılacak, belirli meta verilerden arındırılmış metin dokümanlarını içerecektir.\n",
        "    * Örnek dokümanların ve kategorilerinin gösterilmesi, yüklenen veri hakkında genel bir fikir edinilmesini sağlar."
      ],
      "metadata": {
        "id": "d59iXTXNuMUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 3: Veri Yükleme ve Hazırlık\n",
        "print(\"20 Newsgroups veri seti yükleniyor...\")\n",
        "# fetch_20newsgroups ve time Hücre 2'de import edilmişti.\n",
        "# documents_ng'yi global kapsamda tanımlıyoruz ki sonraki hücrelerde de kullanılabilsin.\n",
        "global documents_ng, targets_ng, target_names_ng, timestamps_ng\n",
        "\n",
        "# sklearn.datasets'den fetch_20newsgroups fonksiyonunu kullanarak veri setini indiriyoruz.\n",
        "# 'all' subset'i tüm veriyi alır.\n",
        "# 'remove' parametresi ile metinlerden başlık, altbilgi ve alıntıları çıkarıyoruz.\n",
        "# shuffle=True veriyi karıştırır, random_state tekrarlanabilirlik için kullanılır.\n",
        "newsgroups_data = fetch_20newsgroups(subset='all',\n",
        "                                     remove=('headers', 'footers', 'quotes'),\n",
        "                                     shuffle=True,\n",
        "                                     random_state=42)\n",
        "\n",
        "documents_ng = newsgroups_data.data\n",
        "targets_ng = newsgroups_data.target\n",
        "target_names_ng = newsgroups_data.target_names\n",
        "\n",
        "# Bu veri setinde belirli zaman damgaları kullanmayacağımız için None olarak ayarlıyoruz.\n",
        "# BERTopic zaman damgalarını kullanarak zamana bağlı konu modellemesi yapabilir, ancak bu örnekte bu özelliği kullanmayacağız.\n",
        "timestamps_ng = None\n",
        "\n",
        "print(f\"{len(documents_ng)} doküman yüklendi.\")\n",
        "print(\"İlk dokümanın bir kısmı (ilk 500 karakter):\")\n",
        "# İlk dokümanın içeriğinden bir kesit ve orijinal kategorisini gösteriyoruz.\n",
        "print(documents_ng[0][:500].replace('\\n', ' ').strip() + \"...\")\n",
        "print(f\"  Orijinal Kategori: {target_names_ng[targets_ng[0]]} (ID: {targets_ng[0]})\")\n",
        "print(\"\\nVeri seti yükleme ve temel hazırlık (Hücre 3) tamamlandı.\")"
      ],
      "metadata": {
        "id": "aTFdYw81uNcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 4 (BERTopic): BERTopic Modelinin Oluşturulması, Eğitilmesi ve Konu Temsillerinin Güncellenmesi\n",
        "\n",
        "* **Amaç:**\n",
        "    Hazırlanan `documents_ng` metin dokümanları üzerinde BERTopic kullanarak konu modellemesi yapmak. Konu temsillerini `KeyBERTInspired` ile iyileştirerek daha anlamlı ve yorumlanabilir anahtar kelimeler elde etmek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **`CountVectorizer` Tanımlama:** İngilizce için standart stop-word listesini kullanan, kelimelerin en az 5 dokümanda geçmesini (`min_df=5`) ve hem tekil kelimeleri hem de iki kelimelik sıralı grupları (bigram'lar, `ngram_range=(1, 2)`) dikkate alan bir `CountVectorizer` oluşturulur. Bu, konuların kelime temsillerini oluşturmak için kullanılır.\n",
        "    2.  **BERTopic Modeli Başlatma:**\n",
        "        * `embedding_model=\"all-MiniLM-L6-v2\"`: Metinleri vektörlere dönüştürmek için kullanılacak olan önceden eğitilmiş bir Sentence Transformer modeli.\n",
        "        * `vectorizer_model`: Bir önceki adımda tanımlanan `CountVectorizer`.\n",
        "        * `nr_topics=30`: Modelin bulmasını istediğimiz yaklaşık konu sayısı. BERTopic bu sayıyı bir hedef olarak kullanır ve sonuçta biraz farklı sayıda konu bulabilir.\n",
        "        * `min_topic_size=20`: Bir konunun oluşturulabilmesi için gereken minimum doküman sayısı. Bu, çok küçük ve potansiyel olarak gürültülü konuların oluşmasını engeller.\n",
        "        * `calculate_probabilities=True`: Her dokümanın her bir konuya ait olma olasılığının hesaplanmasını sağlar. Bu, daha sonraki analizler ve görselleştirmeler için kullanışlıdır.\n",
        "        * `verbose=True`: Modelin eğitim süreci hakkında bilgi vermesini sağlar.\n",
        "        Bu parametrelerle bir `BERTopic` modeli (`initial_topic_model`) başlatılır.\n",
        "    3.  **Model Eğitimi (`fit_transform`):** `initial_topic_model.fit_transform(documents_ng)` metodu çağrılarak model, sağlanan dokümanlar üzerinde eğitilir. Bu işlem şu adımları içerir:\n",
        "        * Dokümanların gömülmeleri (embeddings) oluşturulur.\n",
        "        * Boyut azaltma (UMAP kullanarak) uygulanır.\n",
        "        * Kümeleme (HDBSCAN kullanarak) yapılır.\n",
        "        * Her küme için konu temsilleri (c-TF-IDF kullanarak) oluşturulur.\n",
        "        * Belirtilen `nr_topics` sayısına göre konu sayısı azaltılır.\n",
        "        Bu işlemin süresi (`fit_duration`) ölçülür.\n",
        "    4.  **Konu Temsillerini `KeyBERTInspired` ile Güncelleme:**\n",
        "        * `KeyBERTInspired(top_n_words=10)`: Konu başına en alakalı 10 kelimeyi seçmek için KeyBERT tabanlı bir temsil modeli oluşturulur. Bu, genellikle daha yorumlanabilir ve anlamlı konu başlıkları üretir.\n",
        "        * `initial_topic_model.update_topics()` metodu, orijinal dokümanlar, mevcut konu atamaları ve yeni temsil modeli ile çağrılarak konuların kelime tanımları iyileştirilir. Bu işlemin süresi (`update_repr_duration`) de ölçülür.\n",
        "    5.  Güncellenmiş model, `topic_model` adlı global bir değişkene atanarak sonraki hücrelerde kullanılabilir hale getirilir.\n",
        "    6.  Modelin bulduğu toplam konu sayısı ve ilk birkaç konunun (outlier'lar hariç) güncellenmiş anahtar kelimeleri, modelin performansını ve konu kalitesini hızlıca değerlendirmek için yazdırılır.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar:**\n",
        "    * BERTopic modelinin başarılı bir şekilde eğitilmesi beklenir. `fit_transform` süresi ve temsil güncelleme süresi loglanır (örneğin, `fit_transform` için ~80-90 saniye, temsil güncelleme için ~5 saniye).\n",
        "    * Modelin, hedeflenen 30 konuya yakın sayıda (örneğin, 29 veya 30 gibi) anlamlı konu (outlier konusu olan -1 hariç) bulması beklenir.\n",
        "    * `topic_model.get_topic_info()` ile elde edilen DataFrame, bulunan konuları, doküman sayılarını ve güncellenmiş anahtar kelime temsillerini gösterir.\n",
        "    * İlk geçerli konunun en önemli 10 anahtar kelimesi (KeyBERT ile güncellenmiş hali) ekrana yazdırılarak kalitatif bir kontrol sağlanır."
      ],
      "metadata": {
        "id": "WJx87AF4uRZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 4: BERTopic Modeli (nr_topics=30, KeyBERTInspired Temsili)\n",
        "\n",
        "# CountVectorizer, BERTopic, KeyBERTInspired, time Hücre 2'de import edilmişti.\n",
        "# documents_ng Hücre 3'te tanımlanmıştı.\n",
        "# Global değişkenleri tanımlayalım ki sonraki hücrelerde de erişilebilsin.\n",
        "global topic_model, topics_ng, probabilities, fit_duration, update_repr_duration, topic_info_df\n",
        "\n",
        "print(\"--- BERTopic Modeli (nr_topics=30) ---\")\n",
        "\n",
        "# 1. Adım: CountVectorizer Tanımlama\n",
        "# İngilizce için stop-word'leri kaldıracak, en az 5 dokümanda geçen kelimeleri alacak\n",
        "# ve hem tek kelimeleri (unigram) hem de iki kelimelik grupları (bigram) dikkate alacak.\n",
        "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=5, ngram_range=(1, 2))\n",
        "\n",
        "# 2. Adım: BERTopic Modelini Başlatma\n",
        "# embedding_model: Metinleri vektörlere dönüştürmek için kullanılacak model.\n",
        "# vectorizer_model: Kelime frekanslarını hesaplamak için.\n",
        "# nr_topics: Hedeflenen konu sayısı (BERTopic bu sayıyı bir kılavuz olarak kullanır).\n",
        "# min_topic_size: Bir konunun oluşturulabilmesi için gereken minimum doküman sayısı.\n",
        "# calculate_probabilities: Her dokümanın her konuya ait olma olasılığını hesaplar.\n",
        "# verbose=True: Eğitim sırasında ilerleme bilgisini gösterir.\n",
        "initial_topic_model = BERTopic(\n",
        "    embedding_model=\"all-MiniLM-L6-v2\",\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    nr_topics=30,\n",
        "    min_topic_size=20,\n",
        "    calculate_probabilities=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 3. Adım: Modeli Eğitme\n",
        "print(\"\\nBERTopic modeli (nr_topics=30) eğitiliyor...\")\n",
        "start_time_fit = time.time()\n",
        "# fit_transform metodu, belgeleri alır, konuları çıkarır ve her belge için konu atamalarını döndürür.\n",
        "# Aynı zamanda olasılıkları da hesaplar (calculate_probabilities=True ise).\n",
        "topics_ng, probabilities = initial_topic_model.fit_transform(documents_ng)\n",
        "end_time_fit = time.time()\n",
        "fit_duration = end_time_fit - start_time_fit\n",
        "print(f\"Modelin ilk eğitimi (fit_transform) {fit_duration:.2f} saniyede tamamlandı.\")\n",
        "\n",
        "# 4. Adım: Konu Temsillerini KeyBERTInspired ile Güncelleme\n",
        "# Konu temsillerini daha okunabilir ve anlamlı hale getirmek için KeyBERTInspired kullanılır.\n",
        "# top_n_words: Her konu için en önemli kaç kelimenin seçileceğini belirtir.\n",
        "print(\"\\n--- Konu Temsilleri KeyBERTInspired ile Güncelleniyor ---\")\n",
        "keybert_representation_model = KeyBERTInspired(top_n_words=10)\n",
        "\n",
        "start_time_update_repr = time.time()\n",
        "# update_topics metodu, mevcut konuların kelime temsillerini yeniden hesaplar.\n",
        "initial_topic_model.update_topics(\n",
        "    docs=documents_ng, # Modelin konuları doküman içeriğine göre güncellemesi için dokümanlar tekrar verilir.\n",
        "    topics=topics_ng,  # Mevcut konu atamaları da verilir.\n",
        "    representation_model=keybert_representation_model\n",
        ")\n",
        "end_time_update_repr = time.time()\n",
        "update_repr_duration = end_time_update_repr - start_time_update_repr\n",
        "print(f\"Konu temsillerinin güncellenmesi {update_repr_duration:.2f} saniyede tamamlandı.\")\n",
        "\n",
        "# Güncellenmiş modeli ana değişkenimize atayalım\n",
        "topic_model = initial_topic_model\n",
        "\n",
        "print(\"\\n--- Güncellenmiş Model Bilgileri (KeyBERTInspired Temsili) ---\")\n",
        "# topic_model.get_topic_info() metodu, modeldeki tüm konular hakkında bilgi içeren bir DataFrame döndürür.\n",
        "topic_info_df = topic_model.get_topic_info()\n",
        "print(\"Bulunan Konular (İlk 10 ve Aykırı Değerler - Outlier):\")\n",
        "# Colab'da DataFrame'lerin daha güzel görünmesi için display kullanılır.\n",
        "# Eğer 'display' fonksiyonu mevcutsa onu kullan, değilse standart print ile string'e çevir.\n",
        "# Bu, Jupyter Notebook/Lab veya IPython konsolu gibi ortamlarda daha zengin bir çıktı sağlar.\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(topic_info_df.head(11))\n",
        "except ImportError:\n",
        "    print(topic_info_df.head(11).to_string())\n",
        "\n",
        "\n",
        "# İlk geçerli konunun (outlier olmayan) güncellenmiş anahtar kelimelerini gösterelim.\n",
        "# Outlier konusu genellikle -1 ID'si ile temsil edilir.\n",
        "first_valid_topic_info = topic_info_df[topic_info_df.Topic != -1]\n",
        "if not first_valid_topic_info.empty:\n",
        "    first_valid_topic_id = first_valid_topic_info.Topic.iloc[0]\n",
        "    print(f\"\\nİlk geçerli konu ({first_valid_topic_id}) için GÜNCELLENMİŞ anahtar kelimeler:\")\n",
        "    print(topic_model.get_topic(first_valid_topic_id))\n",
        "else:\n",
        "    print(\"\\nUYARI: Güncellenmiş modelde outlier olmayan hiçbir konu bulunamadı.\")\n",
        "\n",
        "# Outlier'ları (-1) hariç tutarak gerçek konu sayısını hesaplayalım.\n",
        "actual_num_topics = len(topic_info_df[topic_info_df.Topic != -1])\n",
        "print(f\"\\nModelde bulunan gerçek konu sayısı (outlier'lar hariç): {actual_num_topics}\")"
      ],
      "metadata": {
        "id": "leGJPvnvuSQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 5 (BERTopic): Konu Kalitesi Metriklerinin Hesaplanması (BERTopic Vektörleyicisi ile)\n",
        "\n",
        "* **Amaç:**\n",
        "    BERTopic modeli tarafından üretilen (ve temsilleri güncellenmiş) konuların kalitesini Konu Tutarlılığı (C_v, C_UCI/C_NPMI, U_MASS) ve Konu Farklılığı (Jaccard, PUW) metrikleriyle değerlendirmek.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **Konu Kelimeleri Hazırlama:** Önceki hücrede oluşturulan `topic_model`'dan geçerli konular (`Topic != -1`) için en sık geçen `top_n_words_for_coherence` (varsayılan olarak 10) kelimeden oluşan listeler (`bertopic_topics_word_lists`) oluşturulur. Bu listeler, tutarlılık hesaplamaları için kullanılacaktır. Kelimelerin string olduğundan ve boş olmadığından emin olmak için bir kontrol eklenmiştir.\n",
        "    2.  **Doküman Tokenizasyonu (BERTopic `CountVectorizer` ile):** Orijinal dokümanlar (`documents_ng`), BERTopic modelinin `vectorizer_model`'ı (Hücre 4'te tanımlanan `CountVectorizer`) kullanılarak token listelerine dönüştürülür. Bu, tutarlılık metriklerinin, modelin kelimeleri gördüğü şekliyle hesaplanmasını sağlar.\n",
        "    3.  **Gensim Hazırlığı:**\n",
        "        * Tokenleştirilmiş dokümanlardan `gensim.corpora.dictionary.Dictionary` (sözlük) oluşturulur.\n",
        "        * Sözlük, çok nadir (`no_below=3`) veya çok sık (`no_above=0.6`) görünen kelimeleri ve kelime dağarcığı boyutunu sınırlamak (`keep_n=50000`) için filtrelenir.\n",
        "        * Bu sözlük kullanılarak bir Bag-of-Words (BoW) `corpus` (`corpus_bow_for_gensim`) oluşturulur. Bu, özellikle U_MASS tutarlılık metriği için gereklidir.\n",
        "    4.  **Konu Tutarlılığı Metrikleri:** `gensim.models.coherencemodel.CoherenceModel` kullanılarak aşağıdaki metrikler hesaplanır:\n",
        "        * `c_v`: Kelime vektörlerine dayalı bir tutarlılık ölçüsü.\n",
        "        * `c_uci`: Kelimelerin aynı dokümanlarda birlikte görülme sıklığına dayalı bir ölçü.\n",
        "        * `c_npmi`: Normalleştirilmiş noktasal karşılıklı bilgiye dayalı bir ölçü.\n",
        "        * `u_mass`: Dokümanlardaki kelime çiftlerinin olasılıklarına dayalı bir ölçü.\n",
        "    5.  **Konu Farklılığı Metrikleri:**\n",
        "        * **Ortalama Pairwise Jaccard Uzaklığı:** Konu çiftleri arasındaki kelime listelerinin ne kadar farklı olduğunu ölçer (1 - Jaccard Benzerliği). Yüksek değerler daha iyi ayrışmayı gösterir.\n",
        "        * **Benzersiz Kelime Oranı (PUW - Percentage of Unique Words):** Tüm konuların en iyi N kelimesi arasında, toplam kelime sayısına göre benzersiz kelimelerin yüzdesini hesaplar. Yüksek bir değer, konuların daha az örtüştüğünü gösterir.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar:**\n",
        "    * Tokenizasyon ve `gensim` için gerekli veri yapılarının başarıyla oluşturulması beklenir.\n",
        "    * **Konu Tutarlılık Skorları:**\n",
        "        * `C_V` skorunun pozitif ve 0.5'in üzerinde olması genellikle iyi bir anlamsal tutarlılığa işaret eder. Örnek çıktıda ~0.67-0.72 aralığındadır.\n",
        "        * `C_UCI`, `C_NPMI`, ve `U_MASS` metrikleri için elde edilen değerler (örneğin, C_UCI ve U_MASS için negatif, C_NPMI için 0'a yakın pozitif) bazen yorumlanması zor olabilir veya BERTopic'in yapısıyla tam uyumlu olmayabilir. Örnek çıktıda bu metrikler hesaplanabilmiştir.\n",
        "    * **Konu Farklılığı Skorları:**\n",
        "        * Ortalama Pairwise Jaccard Uzaklığı'nın 1'e yakın olması (örneğin, ~0.998) konuların kelime bazında birbirinden oldukça farklı olduğunu gösterir.\n",
        "        * Benzersiz Kelime Oranı (PUW) değerinin yüksek olması (örneğin, ~0.94-0.96) da konuların belirgin ve çeşitli olduğunu destekler."
      ],
      "metadata": {
        "id": "hOXruSD8vXv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 5 (BERTopic): Konu Kalitesi Metriklerinin Hesaplanması (Format Kontrolü ve Son Deneme)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "try:\n",
        "    import gensim\n",
        "    from gensim.models.coherencemodel import CoherenceModel\n",
        "    from gensim.corpora.dictionary import Dictionary\n",
        "except ImportError as e:\n",
        "    print(f\"HATA: Gensim import edilemedi: {e}\")\n",
        "    raise SystemExit(f\"Kritik kütüphane import hatası: {e}\")\n",
        "\n",
        "if 'topic_model' in globals() and topic_model is not None and \\\n",
        "   'documents_ng' in globals() and documents_ng is not None:\n",
        "\n",
        "    print(\"\\n--- Konu Kalitesi Metrikleri Hesaplanıyor (Format Kontrolü ile) ---\")\n",
        "\n",
        "    top_n_words_for_coherence = 10\n",
        "    bertopic_topics_word_lists = []\n",
        "\n",
        "    # topic_model.get_topics() bir sözlük döndürür: {topic_id: [(word, score), ...]}\n",
        "    # Sadece geçerli konuları (outlier olmayanları ve kelime içerenleri) alalım\n",
        "    raw_topics = topic_model.get_topics()\n",
        "    valid_topics_dict = {\n",
        "        k: v for k, v in raw_topics.items() if k != -1 and v  # v (kelime listesi) boş değilse\n",
        "    }\n",
        "\n",
        "    if not valid_topics_dict:\n",
        "        print(\"UYARI: Modelde geçerli konu (kelimeleri olan) bulunamadı. Metrikler atlanıyor.\")\n",
        "    else:\n",
        "        print(f\"{len(valid_topics_dict)} adet geçerli konu bulundu (outlier hariç).\")\n",
        "        for topic_id in sorted(valid_topics_dict.keys()):\n",
        "            words_scores = valid_topics_dict[topic_id]\n",
        "            # Kelimelerin string olduğundan ve listenin boş olmadığından emin olalım\n",
        "            current_topic_words = [str(word) for word, score in words_scores[:top_n_words_for_coherence] if isinstance(word, str) and word.strip() != \"\"]\n",
        "            if current_topic_words: # Sadece boş olmayan kelime listelerini ekle\n",
        "                bertopic_topics_word_lists.append(current_topic_words)\n",
        "\n",
        "        print(f\"Konu tutarlılığı için {len(bertopic_topics_word_lists)} geçerli konu kelime listesi oluşturuldu.\")\n",
        "        if bertopic_topics_word_lists:\n",
        "            print(\"İlk konunun kelime listesi örneği (format kontrolü sonrası):\", bertopic_topics_word_lists[0])\n",
        "        else:\n",
        "            print(\"UYARI: Tutarlılık için işlenecek geçerli konu kelime listesi yok.\")\n",
        "\n",
        "\n",
        "        if not bertopic_topics_word_lists: # Eğer hala boşsa, coherence hesaplama\n",
        "            print(\"Konu tutarlılık metrikleri hesaplanamıyor (geçerli konu kelimesi yok).\")\n",
        "        else:\n",
        "            tokenized_documents_for_gensim = []\n",
        "            gensim_dictionary = None\n",
        "            corpus_bow_for_gensim = []\n",
        "\n",
        "            print(\"\\nDokümanlar BERTopic'in CountVectorizer'ı ile token'larına ayrılıyor...\")\n",
        "            try:\n",
        "                if hasattr(topic_model, 'vectorizer_model') and topic_model.vectorizer_model is not None:\n",
        "                    analyzer = topic_model.vectorizer_model.build_analyzer()\n",
        "                    tokenized_documents_for_gensim = [analyzer(doc) for doc in tqdm(documents_ng, desc=\"Tokenizing with BERTopic's Vectorizer\")]\n",
        "                    print(\"Dokümanlar BERTopic vektörleyicisi ile başarıyla token'laştırıldı.\")\n",
        "\n",
        "                    print(\"Gensim sözlüğü ve corpus oluşturuluyor...\")\n",
        "                    gensim_dictionary = Dictionary(tokenized_documents_for_gensim)\n",
        "                    # Kelimeleri filtrele: en az 3 dokümanda geçen ve en fazla %60'ında geçen kelimeleri tut,\n",
        "                    # ve en fazla 50000 kelimeyi tut. Bu değerler veri setine göre ayarlanabilir.\n",
        "                    gensim_dictionary.filter_extremes(no_below=3, no_above=0.6, keep_n=50000)\n",
        "\n",
        "                    corpus_bow_for_gensim = [gensim_dictionary.doc2bow(doc) for doc in tokenized_documents_for_gensim]\n",
        "                    print(f\"Gensim sözlüğünde {len(gensim_dictionary)} kelime var (filtreleme sonrası).\")\n",
        "\n",
        "                    if not corpus_bow_for_gensim and len(tokenized_documents_for_gensim) > 0 :\n",
        "                        print(\"UYARI: Gensim için BoW corpus boş, UMass hesaplanamayabilir.\")\n",
        "                else:\n",
        "                    print(\"HATA: BERTopic modelinde vectorizer_model bulunamadı. Tokenizasyon yapılamıyor.\")\n",
        "                    tokenized_documents_for_gensim = []\n",
        "\n",
        "            except Exception as e_custom_tokenization:\n",
        "                print(f\"HATA: BERTopic vektörleyicisi ile tokenizasyon sırasında: {e_custom_tokenization}\")\n",
        "                tokenized_documents_for_gensim = []\n",
        "\n",
        "            if gensim_dictionary and tokenized_documents_for_gensim and bertopic_topics_word_lists:\n",
        "                coherence_types_to_calculate = ['c_v', 'c_uci', 'c_npmi', 'u_mass']\n",
        "                print(\"\\nKonu Tutarlılık Skorları:\")\n",
        "                for coherence_type in coherence_types_to_calculate:\n",
        "                    if coherence_type == 'u_mass' and not corpus_bow_for_gensim:\n",
        "                        print(f\"  {coherence_type.upper()}: BoW corpus olmadığı için hesaplanamadı.\")\n",
        "                        continue\n",
        "                    try:\n",
        "                        print(f\"  {coherence_type.upper()} hesaplanıyor...\")\n",
        "                        coherence_model_gensim = CoherenceModel(\n",
        "                            topics=bertopic_topics_word_lists,\n",
        "                            texts=tokenized_documents_for_gensim if coherence_type != 'u_mass' else None,\n",
        "                            corpus=corpus_bow_for_gensim if coherence_type == 'u_mass' else None,\n",
        "                            dictionary=gensim_dictionary,\n",
        "                            coherence=coherence_type,\n",
        "                            topn=top_n_words_for_coherence\n",
        "                        )\n",
        "                        score = coherence_model_gensim.get_coherence()\n",
        "                        print(f\"    -> {coherence_type.upper()}: {score:.4f}\")\n",
        "                    except Exception as e_coh_calc:\n",
        "                        print(f\"    -> HATA ({coherence_type.upper()}): {e_coh_calc}\")\n",
        "            elif bertopic_topics_word_lists:\n",
        "                    print(\"Tokenizasyon veya sözlük oluşturma başarısız olduğu için konu tutarlılık metrikleri hesaplanamadı.\")\n",
        "\n",
        "            # Konu Farklılığı Metrikleri\n",
        "            print(\"\\nKonu Farklılık Skorları:\")\n",
        "            if bertopic_topics_word_lists and len(bertopic_topics_word_lists) >= 2:\n",
        "                jaccard_similarities = []\n",
        "                for i, j in combinations(range(len(bertopic_topics_word_lists)), 2):\n",
        "                    topic1_words = set(bertopic_topics_word_lists[i])\n",
        "                    topic2_words = set(bertopic_topics_word_lists[j])\n",
        "                    if not topic1_words and not topic2_words: continue\n",
        "                    intersection_len = len(topic1_words.intersection(topic2_words))\n",
        "                    union_len = len(topic1_words.union(topic2_words))\n",
        "                    if union_len == 0:\n",
        "                        jaccard_similarities.append(1.0 if not topic1_words and not topic2_words else 0.0)\n",
        "                    else:\n",
        "                        jaccard_similarities.append(intersection_len / union_len)\n",
        "\n",
        "                if jaccard_similarities:\n",
        "                    avg_jaccard_similarity = np.mean(jaccard_similarities)\n",
        "                    avg_jaccard_distance = 1 - avg_jaccard_similarity\n",
        "                    print(f\"  Ortalama Pairwise Jaccard Uzaklığı (ilk {top_n_words_for_coherence} kelime üzerinden): {avg_jaccard_distance:.4f}\")\n",
        "                else:\n",
        "                    print(\"  Jaccard uzaklığı hesaplamak için yeterli konu çifti bulunamadı.\")\n",
        "\n",
        "                all_top_n_words_flat = []\n",
        "                for topic_word_list_for_puw in bertopic_topics_word_lists:\n",
        "                    all_top_n_words_flat.extend(topic_word_list_for_puw[:top_n_words_for_coherence])\n",
        "                if all_top_n_words_flat:\n",
        "                    num_unique_top_words = len(set(all_top_n_words_flat))\n",
        "                    num_total_top_words = len(all_top_n_words_flat)\n",
        "                    puw = num_unique_top_words / num_total_top_words if num_total_top_words > 0 else 0.0\n",
        "                    print(f\"  Benzersiz Kelime Oranı (PUW) (ilk {top_n_words_for_coherence} kelime üzerinden): {puw:.4f}\")\n",
        "                else:\n",
        "                    print(\"  PUW hesaplamak için konu kelimeleri bulunamadı.\")\n",
        "            else:\n",
        "                print(\"  Konu farklılığı metrikleri hesaplamak için en az 2 geçerli konu (kelimeleri olan) gereklidir.\")\n",
        "    print(\"\\nBERTopic Konu Kalitesi Metrikleri (Hücre 5) hesaplama denemesi tamamlandı.\")\n",
        "else:\n",
        "    print(\"Hata: 'topic_model' veya 'documents_ng' Hücre 4'te doğru şekilde oluşturulamadı.\")"
      ],
      "metadata": {
        "id": "lMmHngjtvIzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 6 (BERTopic): Konu Modellemesi Sonuçlarının Görselleştirilmesi\n",
        "\n",
        "* **Amaç:**\n",
        "    BERTopic modeli tarafından bulunan konuları, dokümanlarla ilişkilerini ve konuların birbirleriyle olan benzerliklerini çeşitli interaktif grafikler aracılığıyla görselleştirmek. Bu, modelin ürettiği sonuçları daha iyi anlamamıza ve yorumlamamıza yardımcı olur.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    BERTopic kütüphanesinin sunduğu yerleşik görselleştirme fonksiyonları kullanılır:\n",
        "    1.  **`topic_model.visualize_barchart()`:** En önemli (veya seçilen sayıda) konular için anahtar kelimelerin c-TF-IDF skorlarını gösteren çubuk grafikler oluşturur. Her bir konu için en tanımlayıcı kelimeleri ve bu kelimelerin göreceli önemini gösterir. Bu görselleştirme, konuların içeriğini hızlıca anlamak için çok faydalıdır.\n",
        "    2.  **`topic_model.visualize_heatmap()`:** Konular arasındaki benzerlik matrisini bir ısı haritası olarak gösterir. Bu, hangi konuların birbirine daha yakın veya uzak olduğunu anlamamıza yardımcı olur. Bu görselleştirme için modelin `topic_embeddings_` özelliğinin mevcut olması gerekir, bu da genellikle `fit_transform` sırasında otomatik olarak hesaplanır.\n",
        "    3.  **`topic_model.visualize_hierarchy()`:** Konular arasındaki hiyerarşik ilişkileri gösteren bir dendrogram oluşturur. Bu, konuların nasıl gruplandığını ve daha genel veya daha spesifik alt konular olup olmadığını görmemizi sağlar. Bu görselleştirme için de `topic_embeddings_` gereklidir.\n",
        "    4.  **`topic_model.visualize_documents()`:** Dokümanları ve konuları 2 boyutlu bir uzayda (genellikle UMAP ile boyut indirgeme sonrası) gösteren interaktif bir dağılım grafiğidir. Her bir nokta bir dokümanı temsil eder ve renkleri atandıkları konulara göre belirlenir. Bu, konuların doküman uzayında nasıl ayrıştığını ve belirli dokümanların hangi konulara ait olduğunu keşfetmek için kullanışlıdır. Büyük veri kümelerinde performans için `sample` parametresi ile dokümanların bir alt kümesi üzerinde görselleştirme yapılabilir.\n",
        "    5.  **`topic_model.visualize_topics()` (Intertopic Distance Map):** Konuların birbirlerine göre konumlarını ve büyüklüklerini (doküman sayılarına göre) gösteren interaktif bir harita oluşturur. Bu, konular arasındaki genel ilişkiyi ve göreceli önemlerini görselleştirmek için çok etkilidir ve konu uzayının genel yapısını anlamaya yardımcı olur.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar:**\n",
        "    * Bu hücre çalıştırıldığında, BERTopic tarafından desteklenen çeşitli interaktif (genellikle Plotly kütüphanesi tabanlı) grafikler üretilir.\n",
        "    * Her bir grafik, bulunan konuların farklı bir yönünü görselleştirerek modelin sonuçlarının daha derinlemesine analiz edilmesine olanak tanır.\n",
        "    * Colab ortamında bu interaktif grafikler hücrenin çıktısında doğrudan görüntülenebilir ve incelenebilir. Bu görseller, raporlama ve modelin yorumlanması aşamalarında oldukça değerlidir."
      ],
      "metadata": {
        "id": "8LA_XzesvswV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 6 (BERTopic): Konu Modellemesi Sonuçlarının Görselleştirilmesi\n",
        "\n",
        "# topic_model, documents_ng, topics_ng, probabilities, topic_info_df değişkenlerinin\n",
        "# önceki hücrelerde tanımlandığını ve global olarak erişilebilir olduğunu varsayıyoruz.\n",
        "# matplotlib.pyplot zaten Hücre 2'de import edilmişti.\n",
        "\n",
        "if 'topic_model' in globals() and topic_model is not None and \\\n",
        "   'topic_info_df' in globals() and topic_info_df is not None and \\\n",
        "   'documents_ng' in globals() and documents_ng is not None:\n",
        "\n",
        "    print(\"\\n--- Görselleştirmeler Oluşturuluyor (Güncellenmiş Model) ---\")\n",
        "\n",
        "    # Outlier olmayan geçerli konu sayısını alalım\n",
        "    num_valid_topics_viz = len(topic_info_df[topic_info_df.Topic != -1])\n",
        "\n",
        "    if num_valid_topics_viz > 0:\n",
        "        # 1. Konu Kelime Dağılımları (Çubuk Grafikler)\n",
        "        try:\n",
        "            # Gösterilecek konu sayısını, mevcut geçerli konu sayısıyla veya 10 ile sınırla\n",
        "            num_barchart_topics_to_show = min(10, num_valid_topics_viz)\n",
        "            if num_barchart_topics_to_show > 0 :\n",
        "                print(f\"\\nEn önemli {num_barchart_topics_to_show} konu için Konu Kelime Dağılımları (Çubuk Grafik) oluşturuluyor...\")\n",
        "                fig_barchart = topic_model.visualize_barchart(\n",
        "                    top_n_topics=num_barchart_topics_to_show,\n",
        "                    n_words=10, # Her konu için gösterilecek kelime sayısı\n",
        "                    height=max(300, num_barchart_topics_to_show * 60) # Grafiğin yüksekliğini ayarla\n",
        "                )\n",
        "                fig_barchart.show()\n",
        "            else:\n",
        "                print(\"Çubuk grafik için gösterilecek geçerli konu bulunamadı.\")\n",
        "        except Exception as e_barchart:\n",
        "            print(f\"HATA (visualize_barchart): {e_barchart}\")\n",
        "\n",
        "        # 2. Konu Benzerlik Matrisi (Isı Haritası)\n",
        "        # Bu görselleştirme, topic_model.transform veya fit_transform sırasında\n",
        "        # calculate_probabilities=True ise ve topic_model.probabilities_ None değilse anlamlıdır.\n",
        "        # Ancak BERTopic'in son versiyonlarında visualize_heatmap doğrudan topic_model.topic_embeddings_ kullanabilir.\n",
        "        try:\n",
        "            num_heatmap_topics_to_show = min(30, num_valid_topics_viz) # Gösterilecek konu sayısı\n",
        "            if num_heatmap_topics_to_show > 1: # Isı haritası için en az 2 konu olmalı\n",
        "                print(\"\\nKonu Benzerlik Matrisi (Isı Haritası) oluşturuluyor...\")\n",
        "                fig_heatmap = topic_model.visualize_heatmap(\n",
        "                    top_n_topics=num_heatmap_topics_to_show,\n",
        "                    n_clusters=None, # Kümeleme yapılmayacaksa None\n",
        "                    width=800, height=800\n",
        "                )\n",
        "                fig_heatmap.show()\n",
        "            elif num_heatmap_topics_to_show <=1:\n",
        "                print(\"Isı haritası için gösterilecek yeterli konu (>1) bulunamadı.\")\n",
        "            else:\n",
        "                print(\"Isı haritası için gösterilecek geçerli konu bulunamadı.\")\n",
        "        except Exception as e_heatmap:\n",
        "            print(f\"HATA (visualize_heatmap): {e_heatmap}\")\n",
        "\n",
        "\n",
        "        # 3. Konu Hiyerarşisi (Dendrogram)\n",
        "        try:\n",
        "            num_hierarchy_topics_to_show = min(30, num_valid_topics_viz) # Dendrogramda gösterilecek konu sayısı\n",
        "            if num_hierarchy_topics_to_show > 1: # Hiyerarşi için en az 2 konu olmalı\n",
        "                print(\"\\nKonu Hiyerarşisi (Dendrogram) oluşturuluyor...\")\n",
        "                fig_hierarchy = topic_model.visualize_hierarchy(\n",
        "                    top_n_topics=num_hierarchy_topics_to_show,\n",
        "                    width=1000, height=700 # Grafiğin boyutları\n",
        "                )\n",
        "                fig_hierarchy.show()\n",
        "            elif num_hierarchy_topics_to_show <=1 :\n",
        "                 print(\"Konu hiyerarşisi için gösterilecek yeterli konu (>1) bulunamadı.\")\n",
        "        except AttributeError:\n",
        "            print(\"HATA: 'visualize_hierarchy' fonksiyonu bu BERTopic versiyonunda bulunmuyor olabilir veya bir hata oluştu.\")\n",
        "        except Exception as e_hierarchy:\n",
        "            print(f\"HATA (visualize_hierarchy): {e_hierarchy}\")\n",
        "\n",
        "        # 4. Belge Gömüntüsü Görselleştirmesi (Dokümanların Konulara Göre Dağılımı)\n",
        "        if documents_ng is not None:\n",
        "            try:\n",
        "                print(\"\\nBelge Gömüntüsü Görselleştirmesi oluşturuluyor (bu işlem biraz zaman alabilir)...\")\n",
        "                # Eğer çok fazla doküman varsa, performans için örnekleme yapılabilir.\n",
        "                # Örnek: len(documents_ng) > 10000 ise sample_rate_docs = 0.1 (dokümanların %10'u)\n",
        "                sample_rate_docs = 0.05 if len(documents_ng) > 20000 else (0.1 if len(documents_ng) > 5000 else 1.0)\n",
        "                if sample_rate_docs < 1.0 :\n",
        "                      print(f\"  Çok sayıda doküman olduğundan, dokümanların yaklaşık %{int(sample_rate_docs*100)} kadarı örneklenerek görselleştirilecektir.\")\n",
        "\n",
        "                fig_documents = topic_model.visualize_documents(\n",
        "                    docs=documents_ng,\n",
        "                    sample=sample_rate_docs, # Kullanılacak örnekleme oranı (0.0 ile 1.0 arası)\n",
        "                    width=1200, height=750,\n",
        "                    hide_annotations=(sample_rate_docs < 1.0), # Örnekleme yapılıyorsa anotasyonları gizle\n",
        "                    hide_document_hover=(sample_rate_docs < 0.1) # Çok yoğun örneklemede hover bilgilerini gizle\n",
        "                )\n",
        "                fig_documents.show()\n",
        "            except Exception as e_viz_docs:\n",
        "                print(f\"HATA (visualize_documents): {e_viz_docs}\")\n",
        "        else:\n",
        "            print(\"\\nBelge gömüntüsü görselleştirmesi için 'documents_ng' listesi eksik.\")\n",
        "\n",
        "        # 5. Konu Gömüntüsü Görselleştirmesi (Intertopic Distance Map)\n",
        "        try:\n",
        "            print(\"\\nKonular Arası Mesafe Haritası (Intertopic Distance Map) oluşturuluyor...\")\n",
        "            fig_topics_dist = topic_model.visualize_topics(\n",
        "                width=800, height=800\n",
        "            )\n",
        "            fig_topics_dist.show()\n",
        "        except Exception as e_viz_topics:\n",
        "            print(f\"HATA (visualize_topics): {e_viz_topics}\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nGörselleştirme için yeterli sayıda geçerli konu (outlier olmayan) bulunamadı.\")\n",
        "else:\n",
        "    print(\"Hata: Görselleştirmeler için gerekli BERTopic modeli veya doküman/konu bilgileri bulunamadı.\")"
      ],
      "metadata": {
        "id": "MF_5nv_dvobN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hücre 7 (BERTopic): Eğitim/Konu Çıkarma ve Çıkarım Sürelerinin Hesaplanması\n",
        "\n",
        "* **Amaç:**\n",
        "    BERTopic modelinin hem ilk konu çıkarma (`fit_transform` ve konu temsili güncelleme dahil) süresini hem de daha sonra yeni dokümanlar için konu tahmini (çıkarım/inference) hızını belirlemek. Bu metrikler, modelin pratik uygulamalardaki performansını ve verimliliğini değerlendirmek için önemlidir.\n",
        "\n",
        "* **Yapılan İşlemler:**\n",
        "    1.  **Konu Çıkarma Süresi:**\n",
        "        * Daha önceki hücrelerde (Hücre 4) model eğitimi (`fit_transform`) sırasında ölçülen `fit_duration` ve konu temsillerinin güncellenmesi (`update_topics`) sırasında ölçülen `update_repr_duration` süreleri kullanılır.\n",
        "        * Bu iki süre toplanarak toplam konu çıkarma ve temsil oluşturma süresi hesaplanır ve hem saniye hem de dakika cinsinden kullanıcıya sunulur.\n",
        "    2.  **Yeni Dokümanlar İçin Ortalama Çıkarım Süresi:**\n",
        "        * Modelin yeni, daha önce görmediği veriler üzerindeki performansını ölçmek için `documents_ng` listesinden temsili bir alt küme (örneğin, 100 doküman) rastgele seçilir. Eğer toplam doküman sayısı belirtilen örneklem sayısından azsa, tüm dokümanlar kullanılır.\n",
        "        * `topic_model.transform()` metodu, seçilen bu örnek dokümanlar için konu atamalarını ve olasılıklarını tahmin etmek amacıyla kullanılır.\n",
        "        * Bu `transform` işleminin toplam süresi `time.time()` kullanılarak ölçülür.\n",
        "        * Ölçülen toplam süre, işlenen doküman sayısına bölünerek doküman başına ortalama çıkarım süresi hesaplanır.\n",
        "        * Ayrıca, saniyede kaç dokümanın işlenebildiği (çıkarım hızı veya verim) de hesaplanarak raporlanır.\n",
        "\n",
        "* **Uygulama Detayları/Sonuçlar:**\n",
        "    * Toplam konu çıkarma (eğitim + temsil güncelleme) süresinin yazdırılması beklenir (örneğin, önceki çıktılarda ~92 saniye civarındaydı). Bu, modelin sıfırdan oluşturulması için gereken toplam zamanı gösterir.\n",
        "    * Yeni dokümanlar için konu tahmini yapılırken, BERTopic'in kendi içindeki ilerleme göstergeleri (genellikle `tqdm` ile) görünebilir, bu da işlemin devam ettiğini belirtir.\n",
        "    * Çıkarım işlemi tamamlandığında, toplam çıkarım süresi, doküman başına ortalama çıkarım süresi (örneğin, 100 doküman için ~0.15 saniye/doküman gibi) ve saniyede işlenen doküman sayısı ekrana yazdırılır. Bu değerler, modelin gerçek zamanlı veya büyük ölçekli uygulamalardaki potansiyel performansını anlamak için önemlidir."
      ],
      "metadata": {
        "id": "lckjzOwZw_-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 7 (BERTopic): Eğitim/Konu Çıkarma ve Çıkarım Sürelerinin Hesaplanması\n",
        "\n",
        "# time modülü Hücre 2'de import edilmişti.\n",
        "# fit_duration ve update_repr_duration değişkenleri Hücre 4'te tanımlanmış ve global yapılmış olmalı.\n",
        "# documents_ng Hücre 3'ten, topic_model Hücre 4'ten gelmeli.\n",
        "from tqdm.auto import tqdm # tqdm, transform metodunun ilerlemesini göstermek için BERTopic tarafından kullanılabilir.\n",
        "\n",
        "print(f\"\\n--- Süre Hesaplamaları (BERTopic) ---\")\n",
        "\n",
        "# 1. Eğitim ve Konu Çıkarma Süresi\n",
        "total_topic_modeling_time = 0\n",
        "# fit_duration ve update_repr_duration değişkenlerinin varlığını ve değerini kontrol edelim\n",
        "if 'fit_duration' in globals() and isinstance(fit_duration, (int, float)):\n",
        "    total_topic_modeling_time += fit_duration\n",
        "    print(f\"BERTopic Modeli İlk Eğitimi (fit_transform) Süresi: {fit_duration:.2f} saniye\")\n",
        "    if 'update_repr_duration' in globals() and isinstance(update_repr_duration, (int, float)):\n",
        "        total_topic_modeling_time += update_repr_duration\n",
        "        print(f\"Konu Temsillerini Güncelleme Süresi: {update_repr_duration:.2f} saniye\")\n",
        "    print(f\"  Toplam Konu Çıkarma ve Temsil Oluşturma Süresi: {total_topic_modeling_time:.2f} saniye ({total_topic_modeling_time/60:.2f} dakika)\")\n",
        "else:\n",
        "    print(\"BERTopic eğitim/konu çıkarma süresi bilgisi (fit_duration) bulunamadı veya geçerli değil.\")\n",
        "\n",
        "\n",
        "# 2. Yeni Dokümanlar İçin Ortalama Çıkarım Süresi\n",
        "if 'topic_model' in globals() and topic_model is not None and \\\n",
        "   'documents_ng' in globals() and documents_ng and len(documents_ng) > 0:\n",
        "\n",
        "    num_docs_for_inference_test = min(100, len(documents_ng))\n",
        "    # Eğer doküman sayısı test edilecek sayıdan fazlaysa, rastgele bir örneklem al.\n",
        "    # Aksi takdirde tüm dokümanları kullan.\n",
        "    if len(documents_ng) > num_docs_for_inference_test:\n",
        "        import random\n",
        "        sample_indices_inference = random.sample(range(len(documents_ng)), num_docs_for_inference_test)\n",
        "        new_docs_sample_inference = [documents_ng[i] for i in sample_indices_inference]\n",
        "    else:\n",
        "        new_docs_sample_inference = documents_ng\n",
        "\n",
        "    actual_num_docs_for_inference = len(new_docs_sample_inference)\n",
        "\n",
        "    if actual_num_docs_for_inference > 0:\n",
        "        print(f\"\\n{actual_num_docs_for_inference} adet doküman için konu tahmini (çıkarım) süresi ölçülüyor...\")\n",
        "\n",
        "        start_time_transform = time.time()\n",
        "        try:\n",
        "            # BERTopic.transform, yeni dokümanlar için konuları ve olasılıkları tahmin eder.\n",
        "            # `probabilities` değişkenini burada tekrar kullanmıyoruz çünkü sadece süre ölçümü yapıyoruz.\n",
        "            # İsterseniz `_` yerine `new_topics, new_probabilities` olarak atayabilirsiniz.\n",
        "            _, _ = topic_model.transform(new_docs_sample_inference)\n",
        "            end_time_transform = time.time()\n",
        "\n",
        "            transform_duration_total = end_time_transform - start_time_transform\n",
        "\n",
        "            if actual_num_docs_for_inference > 0 and transform_duration_total >= 0:\n",
        "                avg_transform_duration_per_doc = transform_duration_total / actual_num_docs_for_inference\n",
        "                docs_per_second_transform = actual_num_docs_for_inference / transform_duration_total if transform_duration_total > 0 else float('inf')\n",
        "\n",
        "                print(f\"  Toplam çıkarım süresi ({actual_num_docs_for_inference} doküman): {transform_duration_total:.4f} saniye\")\n",
        "                print(f\"  Doküman başına ortalama çıkarım süresi: {avg_transform_duration_per_doc:.4f} saniye\")\n",
        "                print(f\"  Saniyede işlenen doküman (çıkarım): {docs_per_second_transform:.2f} doküman/saniye\")\n",
        "            else:\n",
        "                print(\"  Çıkarım süresi doğru hesaplanamadı.\")\n",
        "\n",
        "        except Exception as e_transform:\n",
        "            print(f\"  BERTopic.transform sırasında hata: {e_transform}\")\n",
        "            import traceback\n",
        "            print(traceback.format_exc())\n",
        "    else:\n",
        "        print(\"\\nÇıkarım süresi ölçümü için işlenecek doküman bulunamadı.\")\n",
        "else:\n",
        "    print(\"\\nHata: BERTopic modeli veya doküman listesi bulunamadığı için çıkarım süresi hesaplanamıyor.\")\n",
        "\n",
        "print(\"\\nPerformans metrikleri (Hücre 7) hesaplama işlemi tamamlandı.\")"
      ],
      "metadata": {
        "id": "Pb8kvhPJwsxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}